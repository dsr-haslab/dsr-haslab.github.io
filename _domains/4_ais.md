---
layout: domain
title: "Research"
excerpt: "AI and Systems"
domain_acr: ais
permalink: /research/ais
brief_description: Optimizing AI for systems and systems for AI workloads has become one of the most enticing routes for research as models and data grow and storage configurations may be suboptimal.  AIS research focuses on optimizing and improving systems for AI workloads while finding optimal configurations under volatile workloads.
summary: The challenge of efficiently managing the rapid growth of AI models and data, alongside volatile workloads, emphasizes the need for advanced storage solutions. Addressing this, our research focuses on three main areas. First, we aim to design novel storage optimizations tailored for AI workloads, improving the handling of large and complex datasets. Second, we strive to identify optimal storage configurations by leveraging AI techniques, enhancing storage efficiency and security. Third, we focus on optimizing large language models (LLMs) within heterogeneous hierarchies to ensure efficient operation across complex and modern computing environments. These research lines are crucial for advancing AI system capabilities amidst increasing demands and complexity.
goals:
- name: Storage Optimizations for AI Workloads
  description: We aim to design and implement advanced storage mechanisms specifically tailored for AI workloads to handle large and complex datasets more effectively. By assessing bottlenecks in existing storage systems when handling AI workloads, we develop algorithms that optimize data placement, access patterns, and retrieval processes for AI applications.
- name: AI-based Optimal Storage Configurations
  description: While using AI-driven methods, we aim to find and maintain optimal storage configurations, ensuring efficient data management and security by offering self-optimizing storage solutions. Our goal is to create adaptive storage systems that can dynamically reconfigure based on workload characteristics and performance metrics, to enhance storage efficiency and data integrity.
- name: Large Language Models (LLMs) Optimizations
  description: We aim to enhance the performance and efficiency of LLMs operating in diverse and complex computing environments. By analyzing the interaction between LLMs, different levels of storage hierarchies, and CPU-GPU data and model transfer, we aim to develop techniques to optimize memory usage, data transfer, and processing speed for LLMs.
contact: claudia.v.brito
classes: wide
sitemap: false
author_profile: false
header:
  overlay_color: "#000"
  overlay_filter: "0.5"
---

<script
      src="https://code.jquery.com/jquery-3.4.1.min.js"
      integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo="
      crossorigin="anonymous"
    ></script>
<script src="https://unpkg.com/magic-grid/dist/magic-grid.min.js"></script>
